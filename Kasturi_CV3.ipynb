{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8131137,"sourceType":"datasetVersion","datasetId":4805966}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Image segmentation using U-Net\nReferences:\n- [Guide](https://medium.com/@alessandromondin/semantic-segmentation-with-pytorch-u-net-from-scratch-502d6565910a)\n- [Handling COCO dataset](https://www.kaggle.com/code/armanasgharpoor1993/coco-dataset-tutorial-image-segmentation)\n- [Generating class-wise masks](https://github.com/Tramac/awesome-semantic-segmentation-pytorch/blob/master/core/data/dataloader/mscoco.py)","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\n!pip install fiftyone pycocotools\nimport numpy as np\nimport os, sys \nfrom importlib import reload\nimport matplotlib.pyplot as plt\nimport fiftyone as fo \nimport fiftyone.zoo as foz\nfrom tqdm import tqdm \n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms as T\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset\nfrom  torchvision.transforms import InterpolationMode\n\nfrom PIL import Image\nfrom pycocotools.coco import COCO\nfrom pycocotools import mask","metadata":{"execution":{"iopub.status.busy":"2024-04-16T05:33:45.196022Z","iopub.execute_input":"2024-04-16T05:33:45.196656Z","iopub.status.idle":"2024-04-16T05:35:18.825045Z","shell.execute_reply.started":"2024-04-16T05:33:45.196625Z","shell.execute_reply":"2024-04-16T05:35:18.824126Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting fiftyone\n  Downloading fiftyone-0.23.8-py3-none-any.whl.metadata (12 kB)\nCollecting pycocotools\n  Downloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nRequirement already satisfied: aiofiles in /opt/conda/lib/python3.10/site-packages (from fiftyone) (22.1.0)\nCollecting argcomplete (from fiftyone)\n  Downloading argcomplete-3.3.0-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from fiftyone) (4.12.2)\nRequirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (from fiftyone) (1.26.100)\nRequirement already satisfied: cachetools in /opt/conda/lib/python3.10/site-packages (from fiftyone) (4.2.4)\nCollecting dacite<1.8.0,>=1.6.0 (from fiftyone)\n  Downloading dacite-1.7.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: Deprecated in /opt/conda/lib/python3.10/site-packages (from fiftyone) (1.2.14)\nCollecting ftfy (from fiftyone)\n  Downloading ftfy-6.2.0-py3-none-any.whl.metadata (7.3 kB)\nCollecting humanize (from fiftyone)\n  Downloading humanize-4.9.0-py3-none-any.whl.metadata (7.9 kB)\nCollecting hypercorn>=0.13.2 (from fiftyone)\n  Downloading hypercorn-0.16.0-py3-none-any.whl.metadata (5.4 kB)\nRequirement already satisfied: Jinja2>=3 in /opt/conda/lib/python3.10/site-packages (from fiftyone) (3.1.2)\nCollecting kaleido!=0.2.1.post1 (from fiftyone)\n  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (15 kB)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from fiftyone) (3.7.5)\nCollecting mongoengine==0.24.2 (from fiftyone)\n  Downloading mongoengine-0.24.2-py3-none-any.whl.metadata (6.7 kB)\nCollecting motor>=2.5 (from fiftyone)\n  Downloading motor-3.4.0-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fiftyone) (1.26.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from fiftyone) (21.3)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from fiftyone) (2.1.4)\nRequirement already satisfied: Pillow>=6.2 in /opt/conda/lib/python3.10/site-packages (from fiftyone) (9.5.0)\nRequirement already satisfied: plotly>=4.14 in /opt/conda/lib/python3.10/site-packages (from fiftyone) (5.18.0)\nCollecting pprintpp (from fiftyone)\n  Downloading pprintpp-0.4.0-py2.py3-none-any.whl.metadata (7.9 kB)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from fiftyone) (5.9.3)\nRequirement already satisfied: pymongo>=3.12 in /opt/conda/lib/python3.10/site-packages (from fiftyone) (3.13.0)\nRequirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from fiftyone) (2023.3.post1)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from fiftyone) (6.0.1)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from fiftyone) (2023.12.25)\nRequirement already satisfied: retrying in /opt/conda/lib/python3.10/site-packages (from fiftyone) (1.3.3)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from fiftyone) (1.2.2)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from fiftyone) (0.22.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from fiftyone) (1.11.4)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from fiftyone) (69.0.3)\nCollecting sseclient-py<2,>=1.7.2 (from fiftyone)\n  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl.metadata (2.0 kB)\nCollecting sse-starlette<1,>=0.10.3 (from fiftyone)\n  Downloading sse_starlette-0.10.3-py3-none-any.whl.metadata (4.3 kB)\nRequirement already satisfied: starlette>=0.24.0 in /opt/conda/lib/python3.10/site-packages (from fiftyone) (0.32.0.post1)\nCollecting strawberry-graphql==0.138.1 (from fiftyone)\n  Downloading strawberry_graphql-0.138.1-py3-none-any.whl.metadata (7.0 kB)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from fiftyone) (0.9.0)\nCollecting xmltodict (from fiftyone)\n  Downloading xmltodict-0.13.0-py2.py3-none-any.whl.metadata (7.7 kB)\nCollecting universal-analytics-python3<2,>=1.0.1 (from fiftyone)\n  Downloading universal_analytics_python3-1.1.1-py3-none-any.whl.metadata (5.5 kB)\nCollecting fiftyone-brain<0.17,>=0.16.1 (from fiftyone)\n  Downloading fiftyone_brain-0.16.1-py3-none-any.whl.metadata (12 kB)\nCollecting fiftyone-db<2.0,>=0.4 (from fiftyone)\n  Downloading fiftyone_db-1.1.2.tar.gz (7.9 kB)\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting voxel51-eta<0.13,>=0.12.6 (from fiftyone)\n  Downloading voxel51_eta-0.12.6-py2.py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.10/site-packages (from fiftyone) (4.9.0.80)\nCollecting graphql-core<3.3.0,>=3.2.0 (from strawberry-graphql==0.138.1->fiftyone)\n  Downloading graphql_core-3.2.3-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in /opt/conda/lib/python3.10/site-packages (from strawberry-graphql==0.138.1->fiftyone) (2.9.0.post0)\nRequirement already satisfied: typing_extensions<5.0.0,>=3.7.4 in /opt/conda/lib/python3.10/site-packages (from strawberry-graphql==0.138.1->fiftyone) (4.9.0)\nRequirement already satisfied: h11 in /opt/conda/lib/python3.10/site-packages (from hypercorn>=0.13.2->fiftyone) (0.14.0)\nCollecting h2>=3.1.0 (from hypercorn>=0.13.2->fiftyone)\n  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\nCollecting priority (from hypercorn>=0.13.2->fiftyone)\n  Downloading priority-2.0.0-py3-none-any.whl.metadata (6.6 kB)\nCollecting taskgroup (from hypercorn>=0.13.2->fiftyone)\n  Downloading taskgroup-0.0.0a4-py2.py3-none-any.whl.metadata (327 bytes)\nRequirement already satisfied: tomli in /opt/conda/lib/python3.10/site-packages (from hypercorn>=0.13.2->fiftyone) (2.0.1)\nCollecting wsproto>=0.14.0 (from hypercorn>=0.13.2->fiftyone)\n  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from Jinja2>=3->fiftyone) (2.1.3)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fiftyone) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fiftyone) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fiftyone) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fiftyone) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->fiftyone) (3.1.1)\nCollecting pymongo>=3.12 (from fiftyone)\n  Downloading pymongo-4.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\nRequirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from plotly>=4.14->fiftyone) (8.2.3)\nCollecting dnspython<3.0.0,>=1.16.0 (from pymongo>=3.12->fiftyone)\n  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette>=0.24.0->fiftyone) (4.2.0)\nRequirement already satisfied: httpx>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from universal-analytics-python3<2,>=1.0.1->fiftyone) (0.27.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from voxel51-eta<0.13,>=0.12.6->fiftyone) (0.3.8)\nRequirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from voxel51-eta<0.13,>=0.12.6->fiftyone) (1.0.0)\nCollecting glob2 (from voxel51-eta<0.13,>=0.12.6->fiftyone)\n  Downloading glob2-0.7.tar.gz (10 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting jsonlines (from voxel51-eta<0.13,>=0.12.6->fiftyone)\n  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\nCollecting py7zr (from voxel51-eta<0.13,>=0.12.6->fiftyone)\n  Downloading py7zr-0.21.0-py3-none-any.whl.metadata (17 kB)\nCollecting rarfile (from voxel51-eta<0.13,>=0.12.6->fiftyone)\n  Downloading rarfile-4.2-py3-none-any.whl.metadata (4.4 kB)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from voxel51-eta<0.13,>=0.12.6->fiftyone) (2.31.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from voxel51-eta<0.13,>=0.12.6->fiftyone) (1.16.0)\nRequirement already satisfied: sortedcontainers in /opt/conda/lib/python3.10/site-packages (from voxel51-eta<0.13,>=0.12.6->fiftyone) (2.4.0)\nCollecting tzlocal (from voxel51-eta<0.13,>=0.12.6->fiftyone)\n  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\nRequirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from voxel51-eta<0.13,>=0.12.6->fiftyone) (1.26.18)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->fiftyone) (2.5)\nCollecting botocore<1.30.0,>=1.29.100 (from boto3->fiftyone)\n  Downloading botocore-1.29.165-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3->fiftyone) (1.0.1)\nRequirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from boto3->fiftyone) (0.6.2)\nRequirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from Deprecated->fiftyone) (1.14.1)\nRequirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /opt/conda/lib/python3.10/site-packages (from ftfy->fiftyone) (0.2.13)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->fiftyone) (2023.4)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->fiftyone) (3.2.1)\nRequirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image->fiftyone) (2.33.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->fiftyone) (2023.12.9)\nRequirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from scikit-image->fiftyone) (0.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->fiftyone) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->fiftyone) (3.2.0)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (3.6)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (1.3.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (1.2.0)\nCollecting hyperframe<7,>=6.0 (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone)\n  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\nCollecting hpack<5,>=4.0 (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone)\n  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (2024.2.2)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (1.0.5)\nRequirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonlines->voxel51-eta<0.13,>=0.12.6->fiftyone) (23.2.0)\nRequirement already satisfied: texttable in /opt/conda/lib/python3.10/site-packages (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone) (1.7.0)\nCollecting pycryptodomex>=3.16.0 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\nCollecting pyzstd>=0.15.9 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n  Downloading pyzstd-0.15.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\nCollecting pyppmd<1.2.0,>=1.1.0 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n  Downloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\nCollecting pybcj<1.1.0,>=1.0.0 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n  Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nCollecting multivolumefile>=0.2.3 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\nCollecting inflate64<1.1.0,>=1.0.0 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n  Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nCollecting brotli>=1.1.0 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->voxel51-eta<0.13,>=0.12.6->fiftyone) (3.3.2)\nDownloading fiftyone-0.23.8-py3-none-any.whl (7.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading mongoengine-0.24.2-py3-none-any.whl (108 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading strawberry_graphql-0.138.1-py3-none-any.whl (192 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.5/192.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pycocotools-2.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.2/426.2 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading dacite-1.7.0-py3-none-any.whl (12 kB)\nDownloading fiftyone_brain-0.16.1-py3-none-any.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.6/89.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading hypercorn-0.16.0-py3-none-any.whl (59 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading motor-3.4.0-py3-none-any.whl (74 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pymongo-4.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (676 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m676.9/676.9 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sse_starlette-0.10.3-py3-none-any.whl (8.0 kB)\nDownloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\nDownloading universal_analytics_python3-1.1.1-py3-none-any.whl (10 kB)\nDownloading voxel51_eta-0.12.6-py2.py3-none-any.whl (942 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m942.9/942.9 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading argcomplete-3.3.0-py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanize-4.9.0-py3-none-any.whl (126 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.8/126.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\nDownloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\nDownloading botocore-1.29.165-py3-none-any.whl (11.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading h2-4.1.0-py3-none-any.whl (57 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading wsproto-1.2.0-py3-none-any.whl (24 kB)\nDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\nDownloading priority-2.0.0-py3-none-any.whl (8.9 kB)\nDownloading py7zr-0.21.0-py3-none-any.whl (67 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rarfile-4.2-py3-none-any.whl (29 kB)\nDownloading taskgroup-0.0.0a4-py2.py3-none-any.whl (9.1 kB)\nDownloading tzlocal-5.2-py3-none-any.whl (17 kB)\nDownloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading hpack-4.0.0-py3-none-any.whl (32 kB)\nDownloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\nDownloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\nDownloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyzstd-0.15.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (411 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.2/411.2 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: fiftyone-db, glob2\n  Building wheel for fiftyone-db (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fiftyone-db: filename=fiftyone_db-1.1.2-py3-none-manylinux1_x86_64.whl size=37851557 sha256=e571b44f1aca95de70efd56cf5554d36d0f037b7ffb382be8d443b8a2acbebc7\n  Stored in directory: /root/.cache/pip/wheels/29/52/b9/14b9d344410c63c0447ba16bf47c0a064c55d735fa14ecf95c\n  Building wheel for glob2 (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for glob2: filename=glob2-0.7-py2.py3-none-any.whl size=9300 sha256=a2fe7fcf4265998be4e95d560d5e1a1308b31003abcfe52839ddb68c5d310ce8\n  Stored in directory: /root/.cache/pip/wheels/37/07/ce/cbe8d31ad93224571b49fa03f8a5da11cdb31d3845ff73e0f3\nSuccessfully built fiftyone-db glob2\nInstalling collected packages: sseclient-py, pprintpp, kaleido, glob2, brotli, xmltodict, wsproto, tzlocal, taskgroup, rarfile, pyzstd, pyppmd, pycryptodomex, pybcj, priority, multivolumefile, jsonlines, inflate64, hyperframe, humanize, hpack, graphql-core, ftfy, fiftyone-db, dnspython, dacite, argcomplete, strawberry-graphql, pymongo, py7zr, h2, botocore, voxel51-eta, universal-analytics-python3, sse-starlette, pycocotools, motor, mongoengine, hypercorn, fiftyone-brain, fiftyone\n  Attempting uninstall: brotli\n    Found existing installation: Brotli 1.0.9\n    Uninstalling Brotli-1.0.9:\n      Successfully uninstalled Brotli-1.0.9\n  Attempting uninstall: dacite\n    Found existing installation: dacite 1.8.1\n    Uninstalling dacite-1.8.1:\n      Successfully uninstalled dacite-1.8.1\n  Attempting uninstall: pymongo\n    Found existing installation: pymongo 3.13.0\n    Uninstalling pymongo-3.13.0:\n      Successfully uninstalled pymongo-3.13.0\n  Attempting uninstall: botocore\n    Found existing installation: botocore 1.34.51\n    Uninstalling botocore-1.34.51:\n      Successfully uninstalled botocore-1.34.51\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\naiobotocore 2.12.2 requires botocore<1.34.52,>=1.34.41, but you have botocore 1.29.165 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\napache-beam 2.46.0 requires pymongo<4.0.0,>=3.8.0, but you have pymongo 4.6.3 which is incompatible.\nydata-profiling 4.6.4 requires dacite>=1.8, but you have dacite 1.7.0 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed argcomplete-3.3.0 botocore-1.29.165 brotli-1.1.0 dacite-1.7.0 dnspython-2.6.1 fiftyone-0.23.8 fiftyone-brain-0.16.1 fiftyone-db-1.1.2 ftfy-6.2.0 glob2-0.7 graphql-core-3.2.3 h2-4.1.0 hpack-4.0.0 humanize-4.9.0 hypercorn-0.16.0 hyperframe-6.0.1 inflate64-1.0.0 jsonlines-4.0.0 kaleido-0.2.1 mongoengine-0.24.2 motor-3.4.0 multivolumefile-0.2.3 pprintpp-0.4.0 priority-2.0.0 py7zr-0.21.0 pybcj-1.0.2 pycocotools-2.0.7 pycryptodomex-3.20.0 pymongo-4.6.3 pyppmd-1.1.0 pyzstd-0.15.10 rarfile-4.2 sse-starlette-0.10.3 sseclient-py-1.8.0 strawberry-graphql-0.138.1 taskgroup-0.0.0a4 tzlocal-5.2 universal-analytics-python3-1.1.1 voxel51-eta-0.12.6 wsproto-1.2.0 xmltodict-0.13.0\nMigrating database to v0.23.8\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load dataset\n\n# Save to current directory\ncurr_dir = os.getcwd()\nfo.config.dataset_zoo_dir = curr_dir \n\n# Download the data \ndataset = foz.load_zoo_dataset(\"coco-2017\",\n                            splits=['train'],\n                            shuffle=True,\n                            seed=0,\n                            max_samples=10000,\n                            label_type=['segmentations'],\n                            only_matching=True,\n                            classes=['person', 'cat', 'car'])","metadata":{"execution":{"iopub.status.busy":"2024-04-16T05:35:34.938867Z","iopub.execute_input":"2024-04-16T05:35:34.939577Z","iopub.status.idle":"2024-04-16T05:46:37.313791Z","shell.execute_reply.started":"2024-04-16T05:35:34.939544Z","shell.execute_reply":"2024-04-16T05:46:37.312585Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Downloading split 'train' to '/kaggle/working/coco-2017/train' if necessary\nDownloading annotations to '/kaggle/working/coco-2017/tmp-download/annotations_trainval2017.zip'\n 100% |██████|    1.9Gb/1.9Gb [2.5s elapsed, 0s remaining, 761.8Mb/s]      \nExtracting annotations to '/kaggle/working/coco-2017/raw/instances_train2017.json'\nDownloading 10000 images\n 100% |██████████████| 10000/10000 [9.3m elapsed, 0s remaining, 18.6 images/s]       \nWriting annotations for 10000 downloaded samples to '/kaggle/working/coco-2017/train/labels.json'\nDataset info written to '/kaggle/working/coco-2017/info.json'\nIgnoring unsupported parameter 'label_type' for importer type <class 'fiftyone.utils.coco.COCODetectionDatasetImporter'>\nLoading 'coco-2017' split 'train'\n 100% |█████████████| 10000/10000 [55.9s elapsed, 0s remaining, 182.4 samples/s]      \nDataset 'coco-2017-train-10000' created\n","output_type":"stream"}]},{"cell_type":"code","source":"class COCODataset(Dataset):\n    def __init__(self, image_dir, annotation_file, filter_classes, size=None, max_num=None):\n        self.image_dir = image_dir\n        self.filter_classes = filter_classes\n        self.coco = COCO(annotation_file)\n        self.coco_mask = mask \n\n        # Fetch class IDs only corresponding to the filterClasses\n        self.catIds = self.coco.getCatIds(catNms=filter_classes)\n\n        # Get image ID that satisfies the given filter conditions\n        self.ids = self.coco.getImgIds()\n        \n        if max_num != None:\n            self.ids = self.ids[:max_num]\n\n        self.size = size\n        if size != None:\n            self.transform = T.Compose([T.Resize((size, size)), T.ToTensor()])\n            self.mask_transform = T.Compose([T.Resize((size, size), interpolation=Image.NEAREST), \n                                             T.ToTensor()])\n        else:\n            self.transform = T.ToTensor()\n            self.mask_transform = T.ToTensor()\n        \n        self.scale = len(self.catIds)\n        \n    def __len__(self):\n        return len(self.ids)\n\n    def __getitem__(self, idx):\n        img_id = self.ids[idx]\n        ann_ids = self.coco.getAnnIds(imgIds=img_id, catIds=self.catIds)\n        anns = self.coco.loadAnns(ann_ids)\n        img_info = self.coco.loadImgs(img_id)[0]\n\n        img_path = os.path.join(self.image_dir, img_info['file_name'])\n        image = Image.open(img_path).convert('RGB')\n        \n        mask = np.zeros(image.size[::-1], dtype=np.uint8)\n       \n        # 0 is background\n        for ann in anns:\n            idx = self.catIds.index(ann['category_id']) + 1\n            mask = np.maximum(mask, self.coco.annToMask(ann)*idx)\n\n        # Normalize for PyTorch\n        mask = Image.fromarray(mask/len(self.catIds))\n\n        \n        image = self.transform(image)\n        mask = self.mask_transform(mask)\n        \n        return image, mask","metadata":{"execution":{"iopub.status.busy":"2024-04-16T05:46:37.315831Z","iopub.execute_input":"2024-04-16T05:46:37.316188Z","iopub.status.idle":"2024-04-16T05:46:37.331379Z","shell.execute_reply.started":"2024-04-16T05:46:37.316158Z","shell.execute_reply":"2024-04-16T05:46:37.330296Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Dataset loader for PyTorch\n\ndataDir='./coco-2017/'\ndataType='train2017'\n# annFile='{}raw/instances_{}.json'.format(dataDir, dataType)\nannFile='{}/train/labels.json'.format(dataDir)\n\nimageDir = '{}train/data/'.format(dataDir)\nfilter_classes = ['person', 'cat', 'car']\nsize = 128\nmax_num = None\n\n# Initialize the COCO api for instance annotations\ncoco_dataset = COCODataset(imageDir, annFile, filter_classes, size, max_num)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T05:46:45.848550Z","iopub.execute_input":"2024-04-16T05:46:45.848974Z","iopub.status.idle":"2024-04-16T05:46:48.834263Z","shell.execute_reply.started":"2024-04-16T05:46:45.848940Z","shell.execute_reply":"2024-04-16T05:46:48.833133Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"loading annotations into memory...\nDone (t=2.67s)\ncreating index...\nindex created!\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import random_split\n\ntrain_ratio = 0.9\ntotal_length = len(coco_dataset)\ntrain_length = int(train_ratio * total_length)\ntest_length = total_length - train_length\n\ntrain_dataset, test_dataset = random_split(coco_dataset, [train_length, test_length])\n\nbatch_size = 16\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(train_dataset, batch_size=1, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T05:46:54.721705Z","iopub.execute_input":"2024-04-16T05:46:54.722812Z","iopub.status.idle":"2024-04-16T05:46:54.753341Z","shell.execute_reply.started":"2024-04-16T05:46:54.722767Z","shell.execute_reply":"2024-04-16T05:46:54.752196Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"\nclass UNetBlock(nn.Module):\n    def __init__(self, in_channels, mid_channels, out_channels, submodule, kernel=4, stride=2, padding=1, \n                 dropout = False, outermost = False, innermost = False):\n        super(UNetBlock, self).__init__()\n\n        down_conv = nn.Conv2d(in_channels, mid_channels, kernel_size=kernel, stride=stride, padding=padding)\n        down_batchnorm = nn.BatchNorm2d(mid_channels)\n        down_relu = nn.ReLU(inplace=True)\n        up_batchnorm = nn.BatchNorm2d(out_channels)\n        up_relu = nn.ReLU(inplace=True)\n\n        self.outermost = outermost \n\n        if outermost:\n            layers = [down_conv, down_batchnorm, down_relu]\n            layers += [submodule]\n            layers += [nn.ConvTranspose2d(mid_channels*2, out_channels, kernel_size=kernel, stride=stride, padding=padding)]\n            # ## Add final activation - segmentation uses sigmoid\n            # layers += [nn.Sigmoid()]\n            layers += [nn.Softmax(dim=1)]\n        elif innermost:\n            up_conv = nn.ConvTranspose2d(mid_channels, out_channels, kernel_size=kernel, stride=stride, padding=padding)\n            layers = [down_conv, down_batchnorm, down_relu]\n            layers += [up_conv, up_batchnorm, up_relu]\n        else: \n            up_conv = nn.ConvTranspose2d(mid_channels*2, out_channels, kernel_size=kernel, stride=stride, padding=padding)\n            layers = [down_conv, down_batchnorm, down_relu]\n            layers += [submodule]\n            layers += [up_conv, up_batchnorm, up_relu]\n            if dropout: layers += [nn.Dropout(0.4)]\n\n        self.model = nn.Sequential(*layers)\n\n    def forward(self, x):\n        if self.outermost:\n            return self.model(x)\n        else:\n            return torch.cat([x, self.model(x)], axis = 1)\n\nclass UNet(nn.Module):\n    # Exit channels is number of classes\n    def __init__(self, in_channels, first_out_channels, exit_channels, downhill = 4, kernel = 3, stride = 1, padding = 0):\n        super(UNet, self).__init__()\n        \n        num_innermost = first_out_channels*(2**(downhill - 1))\n        num_mid = num_innermost\n        layer = UNetBlock(num_innermost, num_innermost, num_innermost, None, innermost=True)\n        for _ in range(downhill - 1):\n            num_mid //= 2\n            layer = UNetBlock(num_mid, num_mid*2, num_mid, layer)\n            \n        self.model = UNetBlock(in_channels, first_out_channels, exit_channels, layer, outermost=True)\n\n    def forward(self, x):\n        return self.model(x)\n        ","metadata":{"execution":{"iopub.status.busy":"2024-04-16T05:46:58.169650Z","iopub.execute_input":"2024-04-16T05:46:58.170447Z","iopub.status.idle":"2024-04-16T05:46:58.197167Z","shell.execute_reply.started":"2024-04-16T05:46:58.170373Z","shell.execute_reply":"2024-04-16T05:46:58.195800Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Parameters\nlearning_rate = 2e-3\nnum_epochs = 10\nn_down = 4\ninput_channels = 3\nfirst_out_channels = 32\noutput_classes = 4\ndevice = torch.device('cuda')\n\n# 4 classes output - person, cat, car, background\nmodel = UNet(input_channels, first_out_channels, output_classes, n_down)\n\n# Define loss function\ncriterion = torch.hub.load(\n\t'adeelh/pytorch-multi-class-focal-loss',\n\tmodel='focal_loss',\n    # background and person get less weight since car and cat instances are very less\n\talpha=torch.tensor([0.1, 0.2, 0.35, 0.35]),\n\tgamma=2,\n    device=device,\n\treduction='mean',\n    dtype=torch.float32,\n\tforce_reload=False\n)\n \n# Define optimizer\noptimizer = optim.Adam(model.parameters())\n\n# Set device\nmodel= nn.DataParallel(model)\nmodel.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-16T05:47:26.587838Z","iopub.execute_input":"2024-04-16T05:47:26.588917Z","iopub.status.idle":"2024-04-16T05:47:27.143361Z","shell.execute_reply.started":"2024-04-16T05:47:26.588853Z","shell.execute_reply":"2024-04-16T05:47:27.142401Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/adeelh_pytorch-multi-class-focal-loss_master\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DataParallel(\n  (module): UNet(\n    (model): UNetBlock(\n      (model): Sequential(\n        (0): Conv2d(3, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): UNetBlock(\n          (model): Sequential(\n            (0): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n            (3): UNetBlock(\n              (model): Sequential(\n                (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (2): ReLU(inplace=True)\n                (3): UNetBlock(\n                  (model): Sequential(\n                    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n                    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                    (2): ReLU(inplace=True)\n                    (3): UNetBlock(\n                      (model): Sequential(\n                        (0): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n                        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                        (2): ReLU(inplace=True)\n                        (3): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n                        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                        (5): ReLU(inplace=True)\n                      )\n                    )\n                    (4): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n                    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                    (6): ReLU(inplace=True)\n                  )\n                )\n                (4): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n                (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n                (6): ReLU(inplace=True)\n              )\n            )\n            (4): ConvTranspose2d(128, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n            (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (6): ReLU(inplace=True)\n          )\n        )\n        (4): ConvTranspose2d(64, 4, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n        (5): Softmax(dim=1)\n      )\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Training\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    \n    for batch_idx, (images, masks) in tqdm(enumerate(train_loader)):\n        images, masks = images.to(device), masks.to(device)\n\n        # Convert to int masks\n        masks = masks*coco_dataset.scale \n        \n        # Forward pass\n        outputs = model(images)\n        \n        # Calculate loss\n        flattened_output = outputs.reshape([batch_size, output_classes, -1])\n        flattened_masks = masks.reshape([batch_size, -1]).long()\n        loss = criterion(flattened_output, flattened_masks)\n        \n        # Backward pass and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item() * images.size(0)\n    \n    epoch_loss = running_loss / len(coco_dataset)\n    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.6f}')","metadata":{"execution":{"iopub.status.busy":"2024-04-16T05:47:56.308467Z","iopub.execute_input":"2024-04-16T05:47:56.308867Z","iopub.status.idle":"2024-04-16T06:08:39.156524Z","shell.execute_reply.started":"2024-04-16T05:47:56.308837Z","shell.execute_reply":"2024-04-16T06:08:39.155580Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"563it [02:08,  4.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/10], Loss: 0.048828\n","output_type":"stream"},{"name":"stderr","text":"563it [02:03,  4.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/10], Loss: 0.046043\n","output_type":"stream"},{"name":"stderr","text":"563it [02:04,  4.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/10], Loss: 0.045000\n","output_type":"stream"},{"name":"stderr","text":"563it [02:04,  4.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/10], Loss: 0.044102\n","output_type":"stream"},{"name":"stderr","text":"563it [02:04,  4.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5/10], Loss: 0.043147\n","output_type":"stream"},{"name":"stderr","text":"563it [02:03,  4.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [6/10], Loss: 0.042403\n","output_type":"stream"},{"name":"stderr","text":"563it [02:04,  4.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [7/10], Loss: 0.041448\n","output_type":"stream"},{"name":"stderr","text":"563it [02:04,  4.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [8/10], Loss: 0.040495\n","output_type":"stream"},{"name":"stderr","text":"563it [02:03,  4.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [9/10], Loss: 0.039323\n","output_type":"stream"},{"name":"stderr","text":"563it [02:02,  4.59it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [10/10], Loss: 0.038086\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save model for using trained weights in the future\ntorch.save(model.state_dict(), 'trained.pt')","metadata":{"execution":{"iopub.status.busy":"2024-04-16T06:11:09.476184Z","iopub.execute_input":"2024-04-16T06:11:09.476941Z","iopub.status.idle":"2024-04-16T06:11:09.516781Z","shell.execute_reply.started":"2024-04-16T06:11:09.476892Z","shell.execute_reply":"2024-04-16T06:11:09.515668Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def metrics(pred_mask, true_mask):\n    delta = 1e-6 \n\n    intersection = torch.sum(pred_mask & true_mask).item()\n    union = torch.sum(pred_mask | true_mask).item()\n    sum_areas = torch.sum(pred_mask).item() + torch.sum(true_mask).item()\n\n    dice_score = (2*intersection)/(sum_areas + delta)\n    iou_score = intersection/(union + delta)\n    return dice_score, iou_score ","metadata":{"execution":{"iopub.status.busy":"2024-04-16T06:11:14.513142Z","iopub.execute_input":"2024-04-16T06:11:14.514145Z","iopub.status.idle":"2024-04-16T06:11:14.520706Z","shell.execute_reply.started":"2024-04-16T06:11:14.514111Z","shell.execute_reply":"2024-04-16T06:11:14.519495Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Test model \nmodel.eval()\nclasses = {0: \"background\", 1: \"person\", 2: \"car\", 3: \"cat\"}\ndice_sums = {}\niou_sums = {}\n\nfor i in range(len(classes)):\n    dice_sums[i] = []\n    iou_sums[i] = []\ncounter = 10\n\nwith torch.no_grad():\n    for i, (images, masks) in enumerate(test_loader):\n        images, masks = images.to(device), masks.to(device)\n        masks = masks*coco_dataset.scale \n\n        outputs = model(images)\n        \n        predicted_masks = torch.argmax(outputs, dim=1)\n        \n        for key, value in classes.items():\n    \n            class_pred = predicted_masks.flatten() == float(key)\n            class_truth = masks.flatten() == float(key)\n\n           \n                \n            dice, iou = metrics(class_pred, class_truth)\n            \n            dice_sums[key].append(dice) \n            iou_sums[key].append(iou) \n\n        if i == counter:\n            break\nmean_dice = [np.mean(scores) for scores in dice_sums.values()]\nmean_iou = [np.mean(scores) for scores in iou_sums.values()]","metadata":{"execution":{"iopub.status.busy":"2024-04-16T06:11:18.517425Z","iopub.execute_input":"2024-04-16T06:11:18.518362Z","iopub.status.idle":"2024-04-16T06:11:18.838904Z","shell.execute_reply.started":"2024-04-16T06:11:18.518325Z","shell.execute_reply":"2024-04-16T06:11:18.837970Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Average across all classes\nprint(\"Mean Dice Score is\", np.mean(mean_dice))\nprint(\"Mean IoU Score is \", np.mean(mean_iou))","metadata":{"execution":{"iopub.status.busy":"2024-04-16T06:11:22.627665Z","iopub.execute_input":"2024-04-16T06:11:22.628591Z","iopub.status.idle":"2024-04-16T06:11:22.634487Z","shell.execute_reply.started":"2024-04-16T06:11:22.628557Z","shell.execute_reply":"2024-04-16T06:11:22.633480Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Mean Dice Score is 0.36532602667229114\nMean IoU Score is  0.3244981023811271\n","output_type":"stream"}]}]}